{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee1967a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "828ad235",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df = pd.read_csv(\"job_descriptions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4e1456",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b939278",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4281a297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to include\n",
    "columns_to_include = [\n",
    "    'Experience', 'Qualifications', 'Salary Range', 'location',\n",
    "    'Country', 'Work Type', 'Company Size',\n",
    "    'Job Posting Date', 'Preference', 'Contact Person', 'Contact',\n",
    "    'Job Title', 'Role', 'Job Portal', 'Job Description', 'Benefits',\n",
    "    'skills', 'Responsibilities', 'Company'\n",
    "]\n",
    "\n",
    "# Filter job_df to include only the specified columns\n",
    "job_df = job_df[columns_to_include]\n",
    "\n",
    "# Verify the result\n",
    "print(job_df.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675c06bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e46f57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(job_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d67d44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e3e0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff9f001",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df['Job Description'][20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b95685e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Job Posting Date' to datetime\n",
    "job_df['Job Posting Date'] = pd.to_datetime(job_df['Job Posting Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48f6d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df.isnull().sum()\n",
    "job_df.fillna('',inplace=True)\n",
    "job_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54970a8b",
   "metadata": {},
   "source": [
    "# cleaning dataset\n",
    "keeping all letters and digits                          \n",
    "lover case                             \n",
    "removing stopwords                            \n",
    "tokenization                            \n",
    "stemming                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4049f2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import re\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "856403b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(txt):\n",
    "#     step 1\n",
    "    txt = re.sub(r'[^a-zA-Z0-9\\s]','',txt)\n",
    "#     step 2\n",
    "    tokens = nltk.word_tokenize(txt.lower())\n",
    "    # step 3 and 5\n",
    "    stemming = [ps.stem(w) for w in tokens if w not in stopwords.words('english')]\n",
    "    return \" \".join(stemming)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b93699d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning(\"\\n\\rhelo the master piece is my loving moving cat @9032#%$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e179452c",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df_sample = job_df.sample(n=10000)  # Random sample of 10,000 rows for testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "81a56acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Company Size' to integer\n",
    "job_df['Company Size'] = job_df['Company Size'].astype(int)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb7395a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cleaning function to text-based columns\n",
    "text_columns = ['Experience', 'Qualifications', 'Salary Range', 'location', \n",
    "                'Country', 'Work Type', 'Preference', 'Contact Person', \n",
    "                'Contact', 'Job Title', 'Role', 'Job Portal', \n",
    "                'Job Description', 'Benefits', 'skills', 'Responsibilities', 'Company']\n",
    "\n",
    "# Clean each column\n",
    "for col in text_columns:\n",
    "    job_df_sample[col] = job_df_sample[col].astype(str).apply(lambda x: cleaning(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d543106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine cleaned text into a single column\n",
    "job_df_sample['clean_text'] = job_df_sample[text_columns].apply(lambda row: ' '.join(row), axis=1)\n",
    "\n",
    "# Check the combined text\n",
    "print(job_df_sample['clean_text'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cf5f30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5d9bec7",
   "metadata": {},
   "source": [
    "# vectorizatoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7bd5de09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d55d267e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "matrix = tfidf.fit_transform(job_df_sample['clean_text'])\n",
    "similarity = cosine_similarity(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d109c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfd9a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(list(enumerate(similarity[0])), key=lambda x: x[1], reverse=True)[1:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d126d7",
   "metadata": {},
   "source": [
    "# Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3e6749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_jobs():\n",
    "    # Get inputs from the user\n",
    "    job_title = input(\"Enter the job title: \").strip()\n",
    "    work_type = input(\"Enter the work type (e.g., Full-Time, Part-Time, etc.): \").strip()\n",
    "    preference = input(\"Enter your preference (e.g., Remote, Onsite, Hybrid): \").strip()\n",
    "    \n",
    "    # Filter jobs based on work type and preference\n",
    "    filtered_jobs = job_df.copy()\n",
    "    if work_type:\n",
    "        filtered_jobs = filtered_jobs[filtered_jobs['Work Type'].str.contains(work_type, case=False, na=False)]\n",
    "    if preference:\n",
    "        filtered_jobs = filtered_jobs[filtered_jobs['Preference'].str.contains(preference, case=False, na=False)]\n",
    "    \n",
    "    # Ensure the filtered dataset is not empty\n",
    "    if filtered_jobs.empty:\n",
    "        print(\"No jobs found matching the given criteria.\")\n",
    "        return None\n",
    "    \n",
    "    # Get the index of the given title in the filtered dataset\n",
    "    try:\n",
    "        indx = filtered_jobs[filtered_jobs['Job Title'].str.contains(job_title, case=False, na=False)].index[0]\n",
    "        indx = job_df.index.get_loc(indx)  # Original index for similarity\n",
    "    except IndexError:\n",
    "        print(\"The specified job title does not exist in the dataset.\")\n",
    "        return None\n",
    "    \n",
    "    # Compute similarity and sort\n",
    "    distances = sorted(list(enumerate(similarity[indx])), key=lambda x: x[1], reverse=True)[1:20]\n",
    "    \n",
    "    # Collect recommendations\n",
    "    jobs = []\n",
    "    for i in distances:\n",
    "        recommended_job = job_df.iloc[i[0]]\n",
    "        if recommended_job.name in filtered_jobs.index:  # Check if it's in the filtered DataFrame\n",
    "            jobs.append(recommended_job)\n",
    "    \n",
    "    # Convert recommendations to a DataFrame\n",
    "    recommended_df = pd.DataFrame(jobs)\n",
    "    \n",
    "    # Display recommendations\n",
    "    if not recommended_df.empty:\n",
    "        print(\"\\nRecommended Jobs:\")\n",
    "        display_cols = ['Experience', 'Qualifications', 'Salary Range', 'location', \n",
    "                        'Country', 'Work Type', 'Preference', 'Contact Person', \n",
    "                        'Contact', 'Job Title', 'Role', 'Job Portal', \n",
    "                        'Job Description', 'Benefits', 'skills', 'Responsibilities', 'Company']\n",
    "        print(recommended_df[display_cols].head(10))  # Show top 10 recommendations\n",
    "    else:\n",
    "        print(\"No similar jobs found within the filtered criteria.\")\n",
    "    \n",
    "    return recommended_df[display_cols]\n",
    "\n",
    "# Example Usage\n",
    "recommendations = recommend_jobs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a602388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_jobs():\n",
    "    # Get inputs from the user\n",
    "    job_title = input(\"Enter the job title (or leave blank to skip): \").strip()\n",
    "    work_type = input(\"Enter the work type (e.g., Full-Time, Part-Time, etc.) (or leave blank to skip): \").strip()\n",
    "    preference = input(\"Enter your preference (e.g., Female,Male,Both) (or leave blank to skip): \").strip()\n",
    "    \n",
    "    # Start with the complete dataset\n",
    "    filtered_jobs = job_df.copy()\n",
    "\n",
    "    # Apply filters based on inputs\n",
    "    if job_title:\n",
    "        filtered_jobs = filtered_jobs[filtered_jobs['Job Title'].str.contains(job_title, case=False, na=False)]\n",
    "    if work_type:\n",
    "        filtered_jobs = filtered_jobs[filtered_jobs['Work Type'].str.contains(work_type, case=False, na=False)]\n",
    "    if preference:\n",
    "        filtered_jobs = filtered_jobs[filtered_jobs['Preference'].str.contains(preference, case=False, na=False)]\n",
    "    \n",
    "    # Ensure there are matching jobs\n",
    "    if filtered_jobs.empty:\n",
    "        print(\"No jobs found matching the given criteria.\")\n",
    "        return None\n",
    "    \n",
    "    # Display total number of results found\n",
    "    print(f\"\\nTotal number of jobs found: {filtered_jobs.shape[0]}\")\n",
    "    \n",
    "    # Display results in grid format\n",
    "    display_cols = ['Job Title', 'Work Type', 'Preference', 'Experience', 'Qualifications', \n",
    "                    'Salary Range', 'location', 'Country', 'Contact Person', \n",
    "                    'Contact', 'Role', 'Job Portal', 'Job Description', \n",
    "                    'Benefits', 'skills', 'Responsibilities', 'Company']\n",
    "    \n",
    "    filtered_jobs = filtered_jobs[display_cols]\n",
    "    filtered_jobs.reset_index(drop=True, inplace=True)\n",
    "    filtered_jobs.index += 1  # Start numbering from 1\n",
    "    \n",
    "    # Style the DataFrame for presentation\n",
    "    print(\"\\nFiltered Jobs:\")\n",
    "    styled_df = filtered_jobs.style.set_properties(**{\n",
    "        'border': '1px solid black',\n",
    "        'text-align': 'left',\n",
    "        'background-color': '#f9f9f9'\n",
    "    }).set_table_styles([{'selector': 'th', 'props': [('border', '1px solid black'), \n",
    "                                                    ('background-color', '#d9d9d9'), \n",
    "                                                    ('text-align', 'left')]}])\n",
    "    \n",
    "    # Use display() for Jupyter Notebook (if you're in Jupyter environment)\n",
    "    display(styled_df)\n",
    "    \n",
    "    return filtered_jobs\n",
    "\n",
    "# Example Usage\n",
    "recommendations = recommend_jobs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e5e5470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(job_df,open('df.pkl','wb'))\n",
    "pickle.dump(similarity,open('similarity.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239dc57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb0acce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
